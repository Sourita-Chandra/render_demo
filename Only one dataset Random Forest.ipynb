{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47e53db3-f676-40fa-bca8-9549f52038eb",
   "metadata": {},
   "source": [
    "## Only one dataset Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27efb480-9943-4005-9eb1-49c2773c68d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sorted Model Accuracy Scores:\n",
      "Random Forest with accuracy: 0.9705\n",
      "Stacking with accuracy: 0.9659\n",
      "Naive Bayes with accuracy: 0.9636\n",
      "Bagging with accuracy: 0.9591\n",
      "Gradient Boosting with accuracy: 0.9591\n",
      "Decision Tree with accuracy: 0.9523\n",
      "K-Neighbors Classifier with accuracy: 0.9455\n",
      "Support Vector Machine with accuracy: 0.9409\n",
      "Logistic Regression with accuracy: 0.8659\n",
      "AdaBoost with accuracy: 0.1523\n",
      "Accuracy of the Random Forest model on the test set: 96.59%\n",
      "The most suitable crop is 'rice' with a probability of 89.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (BaggingClassifier, \n",
    "                              GradientBoostingClassifier, AdaBoostClassifier, \n",
    "                              StackingClassifier)\n",
    "\n",
    "# Load dataset\n",
    "crop = pd.read_csv(\"Crop_recommendation.csv.csv\")\n",
    "crop_dict = {\n",
    "    'rice': 1, 'maize': 2, 'jute': 3, 'cotton': 4, 'coconut': 5,\n",
    "    'papaya': 6, 'orange': 7, 'apple': 8, 'muskmelon': 9, 'watermelon': 10,\n",
    "    'grapes': 11, 'mango': 12, 'banana': 13, 'pomegranate': 14,\n",
    "    'lentil': 15, 'blackgram': 16, 'mungbean': 17, 'mothbeans': 18,\n",
    "    'pigeonpeas': 19, 'kidneybeans': 20, 'chickpea': 21, 'coffee': 22\n",
    "}\n",
    "\n",
    "# Data preprocessing\n",
    "crop.drop(['rainfall'], axis=1, inplace=True)\n",
    "crop['name'] = crop['label'].map(crop_dict)\n",
    "crop.drop(['label'], axis=1, inplace=True)\n",
    "x = crop.drop('name', axis=1)\n",
    "y = crop['name']\n",
    "\n",
    "# Train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=10)\n",
    "\n",
    "# Scaling\n",
    "ms = MinMaxScaler()\n",
    "ms.fit(x_train)\n",
    "x_train = ms.transform(x_train)\n",
    "x_test = ms.transform(x_test)\n",
    "\n",
    "# Initialize models including stacking\n",
    "models = {\n",
    "        'Logistic Regression': LogisticRegression(),\n",
    "        'Naive Bayes': GaussianNB(),\n",
    "        'Support Vector Machine': SVC(),\n",
    "        'K-Neighbors Classifier': KNeighborsClassifier(),\n",
    "        'Decision Tree': DecisionTreeClassifier(),\n",
    "        'Random Forest': RandomForestClassifier(),\n",
    "        'Bagging': BaggingClassifier(),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(),\n",
    "        'AdaBoost': AdaBoostClassifier(),\n",
    "        \n",
    "        # Stacking Model\n",
    "        'Stacking': StackingClassifier(\n",
    "            estimators=[\n",
    "                ('rf', RandomForestClassifier(n_estimators=200)),\n",
    "                ('svc', SVC(kernel='linear', probability=True))\n",
    "            ], \n",
    "            final_estimator=LogisticRegression()\n",
    "        )\n",
    "}\n",
    "\n",
    "# Store the accuracy of each model in a dictionary\n",
    "model_scores = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred1 = model.predict(x_test)\n",
    "    score = accuracy_score(y_test, y_pred1)\n",
    "    model_scores[name] = score\n",
    "\n",
    "    # Cross-Validation to evaluate the model\n",
    "    cross_val_scores = cross_val_score(model, x_train, y_train, cv=5)\n",
    "       \n",
    "# Sort the models by accuracy score in descending order\n",
    "sorted_model_scores = dict(sorted(model_scores.items(), key=lambda val: val[1], reverse=True))\n",
    "\n",
    "# Print the sorted models with their accuracy scores\n",
    "print(\"\\nSorted Model Accuracy Scores:\")\n",
    "for model, score in sorted_model_scores.items():\n",
    "    print(f\"{model} with accuracy: {score:.4f}\")\n",
    "\n",
    "\n",
    "# Final model\n",
    "rd = RandomForestClassifier()\n",
    "rd.fit(x_train, y_train)\n",
    "# Calculate predictions on the test set\n",
    "y_pred = rd.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy of the Random Forest model on the test set: {accuracy*100:.2f}%\")\n",
    "\n",
    "\n",
    "# Function to load sensor data from a JSON file and calculate the average\n",
    "def get_sensor_data_from_json(json_file):\n",
    "    with open(json_file, 'r') as file:\n",
    "        sensor_data = json.load(file)\n",
    "\n",
    "    # Extract values from the JSON file and group them based on the sequence provided\n",
    "    nitrogen = []\n",
    "    phosphorus = []\n",
    "    potassium = []\n",
    "    temperature = []\n",
    "    humidity = []\n",
    "    ph = []\n",
    "    # Ignore the soil moisture column (5th column)\n",
    "    \n",
    "    for i in range(0, len(sensor_data), 7):  # Assuming each entry has 7 values\n",
    "        nitrogen.append(sensor_data[i])\n",
    "        phosphorus.append(sensor_data[i+1])\n",
    "        potassium.append(sensor_data[i+2])\n",
    "        ph.append(sensor_data[i+3])\n",
    "        temperature.append(sensor_data[i+5])\n",
    "        humidity.append(sensor_data[i+6])\n",
    "\n",
    "    # Calculate the average for each attribute\n",
    "    avg_nitrogen = np.mean(nitrogen)\n",
    "    avg_phosphorus = np.mean(phosphorus)\n",
    "    avg_potassium = np.mean(potassium)\n",
    "    avg_temperature = np.mean(temperature)\n",
    "    avg_humidity = np.mean(humidity)\n",
    "    avg_ph = np.mean(ph)\n",
    "    \n",
    "    return avg_nitrogen, avg_phosphorus, avg_potassium, avg_temperature, avg_humidity, avg_ph\n",
    "\n",
    "\n",
    "# Recommendation function that returns probabilities for multiple crops\n",
    "def recommendation(N, P, K, temperature, humidity, ph):\n",
    "    features = np.array([[N, P, K, temperature, humidity, ph]])\n",
    "    transformed_features = ms.transform(features)\n",
    "    probabilities = rd.predict_proba(transformed_features)  # Get probability for each class\n",
    "    \n",
    "    return probabilities[0]  # Return probabilities for the first (and only) sample\n",
    "\n",
    "# Get sensor input from JSON file and average the data\n",
    "json_file = 'fake.json'  # Replace with your actual JSON file path\n",
    "sensor_data = get_sensor_data_from_json(json_file)\n",
    "\n",
    "# Use the averaged sensor data to get probabilities\n",
    "N, P, K, temperature, humidity, ph = sensor_data  # Unpacking averaged sensor data\n",
    "probabilities = recommendation(N, P, K, temperature, humidity, ph)\n",
    "\n",
    "# Find the index of the crop with the highest probability\n",
    "max_index = np.argmax(probabilities)  # Index of the highest probability\n",
    "highest_probability = probabilities[max_index]\n",
    "\n",
    "# Get the corresponding crop name\n",
    "best_crop = [name for name, val in crop_dict.items() if val == max_index+1][0]\n",
    "\n",
    "# Output the crop with the highest probability\n",
    "print(f\"The most suitable crop is '{best_crop}' with a probability of {highest_probability*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ec63c6a-90e8-462b-b4fd-38d6b70e1455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully as rec_crop.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained Random Forest model\n",
    "joblib.dump(rd, 'rec_crop.pkl')\n",
    "\n",
    "print(\"Model saved successfully as rec_crop.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "336266ec-1959-4fca-911e-b6fc39c59310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most suitable crop is 'rice' with 72.00% probability.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Function to read sensor data from JSON\n",
    "def get_sensor_data_from_json(json_file):\n",
    "    try:\n",
    "        with open(json_file, 'r') as file:\n",
    "            sensor_data = json.load(file)  # Load JSON data\n",
    "\n",
    "        # Ensure JSON structure is valid\n",
    "        if \"data\" not in sensor_data or not isinstance(sensor_data[\"data\"], list):\n",
    "            raise ValueError(\"Invalid JSON structure: Expected 'data' key with a list of readings.\")\n",
    "\n",
    "        # Extract feature values (ignoring soil moisture)\n",
    "        nitrogen, phosphorus, potassium, temperature, humidity, ph = [], [], [], [], [], []\n",
    "\n",
    "        for entry in sensor_data[\"data\"]:\n",
    "            nitrogen.append(entry[\"N\"])\n",
    "            phosphorus.append(entry[\"P\"])\n",
    "            potassium.append(entry[\"K\"])\n",
    "            temperature.append(entry[\"temperature\"])\n",
    "            humidity.append(entry[\"humidity\"])\n",
    "            ph.append(entry[\"ph\"])\n",
    "\n",
    "        # Compute average values\n",
    "        avg_n = np.mean(nitrogen)\n",
    "        avg_p = np.mean(phosphorus)\n",
    "        avg_k = np.mean(potassium)\n",
    "        avg_temp = np.mean(temperature)\n",
    "        avg_humid = np.mean(humidity)\n",
    "        avg_ph = np.mean(ph)\n",
    "\n",
    "        return avg_n, avg_p, avg_k, avg_temp, avg_humid, avg_ph\n",
    "\n",
    "    except (FileNotFoundError, json.JSONDecodeError, KeyError, ValueError) as e:\n",
    "        print(f\"Error reading JSON file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Crop_recommendation.csv\")\n",
    "\n",
    "# Features and labels\n",
    "X = df[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "y = df['label']\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest Model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get sensor data from JSON\n",
    "json_file = 'final.json'\n",
    "sensor_data = get_sensor_data_from_json(json_file)\n",
    "\n",
    "if sensor_data:\n",
    "    N, P, K, temperature, humidity, ph = sensor_data\n",
    "\n",
    "    # Default rainfall value (as it's missing in sensor data)\n",
    "    avg_rainfall = df['rainfall'].mean()\n",
    "\n",
    "    # Make prediction\n",
    "    input_features = [[N, P, K, temperature, humidity, ph, avg_rainfall]]\n",
    "    prediction_probs = rf_model.predict_proba(input_features)\n",
    "    predicted_label_index = np.argmax(prediction_probs)\n",
    "    most_probable_crop = label_encoder.inverse_transform([predicted_label_index])[0]\n",
    "    probability = prediction_probs[0][predicted_label_index]\n",
    "\n",
    "    # Output result\n",
    "    print(f\"The most suitable crop is '{most_probable_crop}' with {probability*100:.2f}% probability.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab203a8f-ea93-46bd-b327-81df25f16220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most suitable crop is 'rice' with 72.00% probability.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Function to read sensor data from JSON\n",
    "def get_sensor_data_from_json(json_file):\n",
    "    try:\n",
    "        with open(json_file, 'r') as file:\n",
    "            sensor_data = json.load(file)  # Load JSON data\n",
    "\n",
    "        # Ensure JSON structure is valid\n",
    "        if \"data\" not in sensor_data or not isinstance(sensor_data[\"data\"], list):\n",
    "            raise ValueError(\"Invalid JSON structure: Expected 'data' key with a list of readings.\")\n",
    "\n",
    "        # Extract feature values (ignoring soil moisture)\n",
    "        nitrogen, phosphorus, potassium, temperature, humidity, ph = [], [], [], [], [], []\n",
    "\n",
    "        for entry in sensor_data[\"data\"]:\n",
    "            nitrogen.append(entry[\"N\"])\n",
    "            phosphorus.append(entry[\"P\"])\n",
    "            potassium.append(entry[\"K\"])\n",
    "            temperature.append(entry[\"temperature\"])\n",
    "            humidity.append(entry[\"humidity\"])\n",
    "            ph.append(entry[\"ph\"])\n",
    "\n",
    "        # Compute average values\n",
    "        avg_n = np.mean(nitrogen)\n",
    "        avg_p = np.mean(phosphorus)\n",
    "        avg_k = np.mean(potassium)\n",
    "        avg_temp = np.mean(temperature)\n",
    "        avg_humid = np.mean(humidity)\n",
    "        avg_ph = np.mean(ph)\n",
    "\n",
    "        return avg_n, avg_p, avg_k, avg_temp, avg_humid, avg_ph\n",
    "\n",
    "    except (FileNotFoundError, json.JSONDecodeError, KeyError, ValueError) as e:\n",
    "        print(f\"Error reading JSON file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Crop_recommendation.csv\")\n",
    "\n",
    "# Features and labels\n",
    "X = df[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "y = df['label']\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest Model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get sensor data from JSON\n",
    "json_file = 'final.json'\n",
    "sensor_data = get_sensor_data_from_json(json_file)\n",
    "\n",
    "if sensor_data:\n",
    "    N, P, K, temperature, humidity, ph = sensor_data\n",
    "\n",
    "    # Default rainfall value (as it's missing in sensor data)\n",
    "    avg_rainfall = df['rainfall'].mean()\n",
    "\n",
    "    # Make prediction\n",
    "    input_features = [[N, P, K, temperature, humidity, ph, avg_rainfall]]\n",
    "    prediction_probs = rf_model.predict_proba(input_features)\n",
    "    predicted_label_index = np.argmax(prediction_probs)\n",
    "    most_probable_crop = label_encoder.inverse_transform([predicted_label_index])[0]\n",
    "    probability = prediction_probs[0][predicted_label_index]\n",
    "\n",
    "    # Output result\n",
    "    print(f\"The most suitable crop is '{most_probable_crop}' with {probability*100:.2f}% probability.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d4d119b-c336-4a78-9e91-c87f7448f70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully as final_crop.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained Random Forest model\n",
    "joblib.dump(rf_model, 'final_crop.pkl')\n",
    "\n",
    "print(\"Model saved successfully as final_crop.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9632fcd8-9e22-415f-a3d3-7515dc20b3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d40010-3491-4305-9a54-1c0f70160a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8effba79-7eb6-468c-9a8a-88822aee75da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de077a3a-37a1-4665-8e63-7e0639a221f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
